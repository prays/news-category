{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "import string\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n",
    "df = pd.read_json('articles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>Liputan6.com, Jakarta - Pertumbuhan startup te...</td>\n",
       "      <td>Kiat Sukses Berbisnis Teknologi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>News</td>\n",
       "      <td>By Eri Komar Sinaga Mantan Kepala Biro Adminis...</td>\n",
       "      <td>KPK Periksa Politikus Demokrat Terkait Korupsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>News</td>\n",
       "      <td>JAKARTA - Komisi Pemilihan Umum (KPU) DKI Jaka...</td>\n",
       "      <td>Pendaftaran Ditutup, KPU Pastikan Pilgub DKI D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekno</td>\n",
       "      <td>ArenaLTE.com - Perkuat industri gaming yang se...</td>\n",
       "      <td>Perkuat Industri Gaming, AMD Akuisisi Pengemba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News</td>\n",
       "      <td>VIVA.co.id - Hingga Senin malam, 26 September ...</td>\n",
       "      <td>Bertambah, Korban Tewas Banjir Garut Jadi 34 O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text  \\\n",
       "0    Tekno  Liputan6.com, Jakarta - Pertumbuhan startup te...   \n",
       "1     News  By Eri Komar Sinaga Mantan Kepala Biro Adminis...   \n",
       "2     News  JAKARTA - Komisi Pemilihan Umum (KPU) DKI Jaka...   \n",
       "3    Tekno  ArenaLTE.com - Perkuat industri gaming yang se...   \n",
       "4     News  VIVA.co.id - Hingga Senin malam, 26 September ...   \n",
       "\n",
       "                                               title  \n",
       "0                    Kiat Sukses Berbisnis Teknologi  \n",
       "1  KPK Periksa Politikus Demokrat Terkait Korupsi...  \n",
       "2  Pendaftaran Ditutup, KPU Pastikan Pilgub DKI D...  \n",
       "3  Perkuat Industri Gaming, AMD Akuisisi Pengemba...  \n",
       "4  Bertambah, Korban Tewas Banjir Garut Jadi 34 O...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    0\n",
       "text        0\n",
       "title       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df['text'],df['category'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_1 = Pipeline ([\n",
    "    ('vect',CountVectorizer()),\n",
    "    ('clf',MultinomialNB(alpha=0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_2 = Pipeline([\n",
    "    ('vect',HashingVectorizer(non_negative=True)),\n",
    "     ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_3 = Pipeline([\n",
    "    ('vect',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf,X,y,K):\n",
    "    cv = KFold(K,shuffle=True,random_state=0)\n",
    "    scores = cross_val_score(clf,X,y,cv=cv)\n",
    "    print(scores)\n",
    "    print(\"Mean score:  {0:.3f} (+/-{1:.3f})\".format(np.mean(scores),sem(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99    0.99375 0.98625 0.9925  0.99   ]\n",
      "Mean score:  0.991 (+/-0.001)\n",
      "[0.98875 0.99125 0.9875  0.9925  0.99   ]\n",
      "Mean score:  0.990 (+/-0.001)\n",
      "[0.9875  0.98875 0.98125 0.995   0.98875]\n",
      "Mean score:  0.988 (+/-0.002)\n"
     ]
    }
   ],
   "source": [
    "clfs = [clf_1,clf_2,clf_3]\n",
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf,df['title'],df['category'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98625 0.99125 0.98875 0.99    0.995  ]\n",
      "Mean score:  0.990 (+/-0.001)\n",
      "[0.9875  0.985   0.98625 0.98625 0.985  ]\n",
      "Mean score:  0.986 (+/-0.000)\n",
      "[0.99    0.98875 0.985   0.985   0.99   ]\n",
      "Mean score:  0.988 (+/-0.001)\n"
     ]
    }
   ],
   "source": [
    "clfs = [clf_1,clf_2,clf_3]\n",
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf,df['text'],df['category'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('stopwords_id.txt','r') as text:\n",
    "    stopwords_id = []\n",
    "    data = text.read().splitlines()\n",
    "    for word in data:\n",
    "        stopwords_id.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_text_process = df['text'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Liputan6com, Jakarta, Pertumbuhan, startup, t...\n",
       "1    [By, Eri, Komar, Sinaga, Mantan, Kepala, Biro,...\n",
       "2    [JAKARTA, Komisi, Pemilihan, KPU, DKI, Jakarta...\n",
       "3    [ArenaLTEcom, Perkuat, industri, gaming, fokus...\n",
       "4    [VIVAcoid, Senin, malam, 26, September, 2016, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_4 = Pipeline ([\n",
    "    ('vect',CountVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_5 = Pipeline([\n",
    "    ('vect',HashingVectorizer(non_negative=True,analyzer=text_process)),\n",
    "     ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_6 = Pipeline([\n",
    "    ('vect',TfidfVectorizer(analyzer=text_process)),\n",
    "    ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98875 0.99    0.99125 0.99    0.995  ]\n",
      "Mean score:  0.991 (+/-0.001)\n",
      "[0.99125 0.99    0.98875 0.98625 0.99375]\n",
      "Mean score:  0.990 (+/-0.001)\n",
      "[0.98875 0.99    0.98875 0.98875 0.99625]\n",
      "Mean score:  0.991 (+/-0.001)\n"
     ]
    }
   ],
   "source": [
    "clfs2 = [clf_4,clf_5,clf_6]\n",
    "for clf in clfs2:\n",
    "    evaluate_cross_validation(clf,df['text'],df['category'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98375 0.9875  0.98625 0.98    0.99125]\n",
      "Mean score:  0.986 (+/-0.002)\n",
      "[0.98625 0.99125 0.99125 0.98875 0.99   ]\n",
      "Mean score:  0.989 (+/-0.001)\n",
      "[0.975   0.98125 0.98125 0.97125 0.98375]\n",
      "Mean score:  0.979 (+/-0.002)\n"
     ]
    }
   ],
   "source": [
    "clfs2 = [clf_4,clf_5,clf_6]\n",
    "for clf in clfs2:\n",
    "    evaluate_cross_validation(clf,df['title'],df['category'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf,X_train,X_test,y_train,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train,y_train))\n",
    "    print('Accuracy on testing set:')\n",
    "    print(clf.score(X_test,y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report\")\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.99875\n",
      "Accuracy on testing set:\n",
      "0.99125\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Bisnis       1.00      0.98      0.99       213\n",
      "     Celebs       1.00      0.99      1.00       183\n",
      "       News       0.98      1.00      0.99       206\n",
      "      Tekno       0.98      0.99      0.99       198\n",
      "\n",
      "avg / total       0.99      0.99      0.99       800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[208   0   3   2]\n",
      " [  0 182   0   1]\n",
      " [  0   0 206   0]\n",
      " [  0   0   1 197]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_1,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.999375\n",
      "Accuracy on testing set:\n",
      "0.99375\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Bisnis       1.00      0.98      0.99       213\n",
      "     Celebs       1.00      0.99      1.00       183\n",
      "       News       0.99      1.00      1.00       206\n",
      "      Tekno       0.99      1.00      0.99       198\n",
      "\n",
      "avg / total       0.99      0.99      0.99       800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[209   0   2   2]\n",
      " [  0 182   0   1]\n",
      " [  0   0 206   0]\n",
      " [  0   0   0 198]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_4,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.994375\n",
      "Accuracy on testing set:\n",
      "0.9925\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Bisnis       1.00      0.99      0.99       213\n",
      "     Celebs       0.99      0.99      0.99       183\n",
      "       News       0.98      1.00      0.99       206\n",
      "      Tekno       0.99      1.00      1.00       198\n",
      "\n",
      "avg / total       0.99      0.99      0.99       800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[210   0   2   1]\n",
      " [  0 181   2   0]\n",
      " [  0   1 205   0]\n",
      " [  0   0   0 198]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_5,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9971875\n",
      "Accuracy on testing set:\n",
      "0.99625\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Bisnis       1.00      0.99      0.99       213\n",
      "     Celebs       1.00      1.00      1.00       183\n",
      "       News       0.99      1.00      1.00       206\n",
      "      Tekno       0.99      1.00      1.00       198\n",
      "\n",
      "avg / total       1.00      1.00      1.00       800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[210   0   2   1]\n",
      " [  0 183   0   0]\n",
      " [  0   0 206   0]\n",
      " [  0   0   0 198]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_6,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = clf_4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as fh:\n",
    "    pickle.dump(model, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('columns.json', 'w') as fh:\n",
    "    json.dump(df[['text']].columns.tolist(), fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dtypes.pickle', 'wb') as fh:\n",
    "    pickle.dump(X_train.dtypes, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
